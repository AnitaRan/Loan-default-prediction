{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import learning_curve,validation_curve\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.metrics import roc_auc_score,auc,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor,plot_importance\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier,callback\n",
    "from catboost import Pool,metrics,cv,MetricVisualizer\n",
    "from catboost.utils import get_roc_curve,select_threshold,get_fpr_curve,get_fnr_curve\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "import shap\n",
    "import Meancoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(data):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() \n",
    "    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "        else:\n",
    "            data[col] = data[col].astype('category')\n",
    "    end_mem = data.memory_usage().sum() \n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv',encoding='utf-8')\n",
    "test_data =pd.read_csv('./data/testA.csv',encoding='utf-8')\n",
    "submission=pd.read_csv('./data/sample_submit.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、数据预处理\n",
    "- 缺失值处理：（1）类别特征：空值用众数填充 （2）离散数值特征：空值用中位数填充\n",
    "- 异常值处理：（1）异常检测方法：均方差，（2）处理:删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(train_data,test_data):    \n",
    "    # 合并数据，方便处理和构造特征  \n",
    "    data = pd.concat([train_data,test_data],ignore_index=True)  \n",
    "    \n",
    "    # 1、分离分类特征和数值特征\n",
    "    # 连续性变量\n",
    "    num_cols = list(train_data.select_dtypes(exclude=['object']).columns)\n",
    "    # 离散型变量\n",
    "    cat_cols = list(train_data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    # 发现分类型变量和时间变量\n",
    "    time_cols = ['issueDate','earliesCreditLine']\n",
    "    cat_cols.remove('issueDate')\n",
    "    cat_cols.remove('earliesCreditLine')\n",
    "    class_cols = ['term','employmentTitle','homeOwnership','verificationStatus', 'purpose',\n",
    "                  'postCode','regionCode','initialListStatus','applicationType','title',]\n",
    "    for col in class_cols:\n",
    "        num_cols.remove(col)\n",
    "        cat_cols.append(col)\n",
    "    num_cols.remove('isDefault')\n",
    "\n",
    "    # 2、缺失值处理\n",
    "    missing = data.drop('isDefault',axis=1).isnull().sum()\n",
    "    missing = missing[missing>0]\n",
    "    missing_df = pd.DataFrame({'missing_key':missing.keys(),'missing_value':np.round(missing.values,4)})\n",
    "\n",
    "    missing_feature = list(missing_df.missing_key)\n",
    "    null_cat,null_num,null_other = [],[],[]\n",
    "    for feat in missing_feature:\n",
    "        if feat in num_cols:\n",
    "            null_num.append(feat)\n",
    "        elif feat in cat_cols:\n",
    "            null_cat.append(feat)\n",
    "        else:\n",
    "            null_other.append(feat)\n",
    "\n",
    "    # 类别特征：空值用众数填充\n",
    "    si_cat = SimpleImputer(strategy='most_frequent').fit(data[null_cat])\n",
    "    data[null_cat] = si_cat.transform(data[null_cat])\n",
    "\n",
    "    # 离散数值特征：空值用中位数填充\n",
    "    si_num = SimpleImputer(strategy='median').fit(data[null_num])\n",
    "    data[null_num] = si_num.transform(data[null_num])\n",
    "\n",
    "    # 3、异常值处理\n",
    "    data['annualIncome'] = data['annualIncome'].apply(lambda x:x if x<283000 else 300000)\n",
    "    data['revolBal'] = data['revolBal'].apply(lambda x:x if x<83000 else 100000)\n",
    "    \n",
    "    income_zero_index = list(data[data['annualIncome']==0].index)\n",
    "    for i in income_zero_index:\n",
    "        data['annualIncome'][i] = (data['loanAmnt'][i]/data['dti'][i])*100\n",
    "     \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preprocessing(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、特征工程\n",
    "- 特征工程\n",
    "    - 数据分桶：\n",
    "    - 特征编码：\n",
    "    - 特征衍生：\n",
    "- 特征融合\n",
    "    - 模型选取：\n",
    "    - 特征筛选："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    # 1.可解释性特征\n",
    "    # 针对时间特征'issueDate'\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d', errors='coerce')\n",
    "    data['issueDate_year'] = data['issueDate'].dt.year\n",
    "    data['issueDate_month'] = data['issueDate'].dt.month.astype('int8')\n",
    "    data['issueDate_dayofweek']= data['issueDate'].dt.dayofweek.astype('int8')\n",
    "\n",
    "    # 针对时间特征'earliesCreditLine'\n",
    "    data['earliesCreditLine_year'] = data['earliesCreditLine'].apply(lambda x:str(x)[str(x).find('-')+1:])\n",
    "    data['earliesCreditLine_month'] = data['earliesCreditLine'].apply(lambda x:str(x)[:str(x).find('-')])\n",
    "    month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7, 'Aug':8, 'Sep':9,'Oct':10,'Nov':11,'Dec':12}       \n",
    "    data['earliesCreditLine_month'] =data['earliesCreditLine_month'].map(month_dict)\n",
    "    data['earliesCreditLine_date'] = data['earliesCreditLine_year'].astype('str') + '-' + data['earliesCreditLine_month'].apply(date_concat)+ '-' + '01'\n",
    "    data['earliesCreditLine_date'] =  pd.to_datetime(data['earliesCreditLine_date'],format='%Y-%m-%d', errors='coerce')\n",
    "    data['Credit_issue_days'] = (data['issueDate'].astype('datetime64') - data['earliesCreditLine_date'].astype('datetime64')).dt.days\n",
    "    data['Credit_issue_years'] = (data['Credit_issue_days']/365).round(2)\n",
    "    del data['issueDate'],data['earliesCreditLine'],data['earliesCreditLine_date'],data['Credit_issue_days']\n",
    "\n",
    "    # 数值特征\n",
    "    # 1) 数值特征:数据分桶\n",
    "    # 通过对数函数映射到指定宽度分箱\n",
    "    data['loanAmnt_bin'] = np.floor(np.log10(data['loanAmnt']))\n",
    "    data['annualIncome_bin'] = np.floor(np.log10(data['annualIncome']))\n",
    "    # 通过除法映射到间隔均匀的分箱中\n",
    "#     data['annualIncome_bin'] = np.floor_divide(data['annualIncome'],1000)\n",
    "\n",
    "    # 2）四则运算组合\n",
    "    data['annual_installment'] = np.ceil(data['installment'] * 12)\n",
    "    data['annual_loanAmnt'] = data['loanAmnt']/data['term']\n",
    "    data['debt_rate'] = ((data['annual_installment']/data['annualIncome'])*100).round(2)\n",
    "    data['debt'] = np.ceil(data['annualIncome'] * data['dti']/100)\n",
    "    del data['annual_installment']\n",
    "\n",
    "    data['pubRec_keep'] = data['pubRec'] - data['pubRecBankruptcies']\n",
    "    data['Acc_keep'] = data['totalAcc'] - data['openAcc']\n",
    "    data['Acc_rate'] = (data['openAcc']/data['totalAcc']).round(3)\n",
    "    data['revolBal/totalAcc'] = (data['revolBal']/data['totalAcc']).round(2)\n",
    "\n",
    "    n_list = ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8','n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n",
    "    n_data = data[n_list]\n",
    "    data['n_sum_1'] = n_data.T.sum().astype('float16')\n",
    "    data['n_sum_2'] = data['n0']+data['n1']+data['n2']+data['n3']+data['n4']-data['n5']-data['n6']+data['n7']-data['n8']+data['n9']+data['n10']-data['n11']+data['n12']+data['n13']+data['n14']\n",
    "\n",
    "    # 部分数值特征归一化\n",
    "    min_max_cols = ['loanAmnt','installment','annualIncome','revolBal','debt']            \n",
    "    scaler = MinMaxScaler().fit(data[min_max_cols])\n",
    "    data[min_max_cols] = pd.DataFrame(scaler.transform(data[min_max_cols]),columns=min_max_cols)\n",
    "\n",
    "    del data['id'],data['policyCode']\n",
    "    del data['loanAmnt'],data['ficoRangeHigh'],data['annualIncome']\n",
    "    del data['n3'],data['n9'],data['n10'],data['n11'],data['n12'],data['n13']\n",
    "\n",
    "    # 2.组合交叉特征\n",
    "    # 离散性特征与连续性特征的一阶交叉\n",
    "    employment_cat = ['homeOwnership','employmentTitle','employmentLength',]\n",
    "    employment_num = ['debt_rate','revolBal',]\n",
    "    data = cross_cat_num(data,employment_cat,employment_num)\n",
    "\n",
    "    debt_cat = ['subGrade','purpose','regionCode',]\n",
    "    debt_num = ['interestRate',]\n",
    "    data = cross_cat_num(data,debt_cat,debt_num)\n",
    "\n",
    "    return data\n",
    " \n",
    "    \n",
    "def date_concat(x):\n",
    "    if len(str(x))==1:\n",
    "        return \"0\"+str(x)\n",
    "    else:\n",
    "        return str(x)\n",
    "    \n",
    "    \n",
    "def cross_cat_num(data,cat_col,num_col):\n",
    "    for f1 in cat_col:\n",
    "        group = data.groupby(f1,as_index=False)\n",
    "        for f2 in num_col:\n",
    "            feat = group[f2].agg({\n",
    "                                 '{}_{}_max'.format(f1,f2):'max',\n",
    "                                 '{}_{}_min'.format(f1,f2):'min',\n",
    "#                                  '{}_{}_median'.format(f1,f2):'median',\n",
    "                                 '{}_{}_mean'.format(f1,f2):'mean',\n",
    "                                 '{}_{}_std'.format(f1,f2):'std',\n",
    "                                '{}_{}_skew'.format(f1,f2):'skew'\n",
    "            })\n",
    "            data = data.merge(feat,how='left',on=f1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_engineering(data)\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isDefault                        1.000000\n",
       "subGrade_interestRate_max        0.263101\n",
       "subGrade_interestRate_mean       0.263101\n",
       "interestRate                     0.254540\n",
       "subGrade_interestRate_std        0.226274\n",
       "                                   ...   \n",
       "homeOwnership_revolBal_mean     -0.071456\n",
       "ficoRangeLow                    -0.130551\n",
       "subGrade_interestRate_skew      -0.135939\n",
       "employmentLength_revolBal_max         NaN\n",
       "employmentLength_revolBal_min         NaN\n",
       "Name: isDefault, Length: 92, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = data.corr('spearman')\n",
    "correlation['isDefault'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示相关性高的变量\n",
    "def getHighRelatedFeature(corr_matrix,corr_threshold):\n",
    "    highRelatedFeature = pd.DataFrame(corr_matrix[corr_matrix > corr_threshold].stack().reset_index())\n",
    "    highRelatedFeature.rename({'level_0':'feature1','level_1':'feature2',0:'corr'},axis=1,inplace=True)\n",
    "    highRelatedFeature = highRelatedFeature[highRelatedFeature.feature1 != highRelatedFeature.feature2]\n",
    "    highRelatedFeature['feature_pair_key'] = highRelatedFeature.loc[:,['feature1','feature2']].apply(lambda x:\"#\".join(np.sort(x.values)),axis=1)\n",
    "    highRelatedFeature.drop_duplicates(subset=['feature_pair_key'],inplace=True)\n",
    "    highRelatedFeature.drop(columns=['feature_pair_key'],inplace=True)\n",
    "    return highRelatedFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>homeOwnership_debt_rate_mean</td>\n",
       "      <td>homeOwnership_debt_rate_std</td>\n",
       "      <td>0.998967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>homeOwnership_debt_rate_max</td>\n",
       "      <td>homeOwnership_debt_rate_std</td>\n",
       "      <td>0.997930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>employmentLength_debt_rate_max</td>\n",
       "      <td>employmentLength_debt_rate_mean</td>\n",
       "      <td>0.997429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>subGrade_interestRate_max</td>\n",
       "      <td>subGrade_interestRate_mean</td>\n",
       "      <td>0.994384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>homeOwnership_debt_rate_max</td>\n",
       "      <td>homeOwnership_debt_rate_mean</td>\n",
       "      <td>0.993987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>employmentLength_debt_rate_max</td>\n",
       "      <td>employmentLength_debt_rate_std</td>\n",
       "      <td>0.989271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>employmentLength_debt_rate_mean</td>\n",
       "      <td>employmentLength_debt_rate_std</td>\n",
       "      <td>0.983711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>homeOwnership_revolBal_mean</td>\n",
       "      <td>homeOwnership_revolBal_std</td>\n",
       "      <td>0.981746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>employmentLength_revolBal_mean</td>\n",
       "      <td>employmentLength_revolBal_std</td>\n",
       "      <td>0.981369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interestRate</td>\n",
       "      <td>subGrade_interestRate_mean</td>\n",
       "      <td>0.977184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>installment</td>\n",
       "      <td>annual_loanAmnt</td>\n",
       "      <td>0.971855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interestRate</td>\n",
       "      <td>subGrade_interestRate_max</td>\n",
       "      <td>0.971703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>employmentTitle_debt_rate_max</td>\n",
       "      <td>employmentTitle_debt_rate_skew</td>\n",
       "      <td>0.970732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeOwnership</td>\n",
       "      <td>homeOwnership_revolBal_skew</td>\n",
       "      <td>0.970069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>subGrade_interestRate_max</td>\n",
       "      <td>subGrade_interestRate_std</td>\n",
       "      <td>0.927852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>homeOwnership_debt_rate_mean</td>\n",
       "      <td>homeOwnership_revolBal_mean</td>\n",
       "      <td>0.922823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>homeOwnership_debt_rate_std</td>\n",
       "      <td>homeOwnership_revolBal_mean</td>\n",
       "      <td>0.904413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>totalAcc</td>\n",
       "      <td>Acc_keep</td>\n",
       "      <td>0.902003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature1                         feature2  \\\n",
       "60      homeOwnership_debt_rate_mean      homeOwnership_debt_rate_std   \n",
       "56       homeOwnership_debt_rate_max      homeOwnership_debt_rate_std   \n",
       "90    employmentLength_debt_rate_max  employmentLength_debt_rate_mean   \n",
       "107        subGrade_interestRate_max       subGrade_interestRate_mean   \n",
       "55       homeOwnership_debt_rate_max     homeOwnership_debt_rate_mean   \n",
       "91    employmentLength_debt_rate_max   employmentLength_debt_rate_std   \n",
       "95   employmentLength_debt_rate_mean   employmentLength_debt_rate_std   \n",
       "72       homeOwnership_revolBal_mean       homeOwnership_revolBal_std   \n",
       "101   employmentLength_revolBal_mean    employmentLength_revolBal_std   \n",
       "3                       interestRate       subGrade_interestRate_mean   \n",
       "5                        installment                  annual_loanAmnt   \n",
       "2                       interestRate        subGrade_interestRate_max   \n",
       "78     employmentTitle_debt_rate_max   employmentTitle_debt_rate_skew   \n",
       "8                      homeOwnership      homeOwnership_revolBal_skew   \n",
       "108        subGrade_interestRate_max        subGrade_interestRate_std   \n",
       "61      homeOwnership_debt_rate_mean      homeOwnership_revolBal_mean   \n",
       "65       homeOwnership_debt_rate_std      homeOwnership_revolBal_mean   \n",
       "23                          totalAcc                         Acc_keep   \n",
       "\n",
       "         corr  \n",
       "60   0.998967  \n",
       "56   0.997930  \n",
       "90   0.997429  \n",
       "107  0.994384  \n",
       "55   0.993987  \n",
       "91   0.989271  \n",
       "95   0.983711  \n",
       "72   0.981746  \n",
       "101  0.981369  \n",
       "3    0.977184  \n",
       "5    0.971855  \n",
       "2    0.971703  \n",
       "78   0.970732  \n",
       "8    0.970069  \n",
       "108  0.927852  \n",
       "61   0.922823  \n",
       "65   0.904413  \n",
       "23   0.902003  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HighRelated_df = getHighRelatedFeature(data.corr(),0.9).sort_values(by='corr',ascending=False)\n",
    "HighRelated_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['homeOwnership_debt_rate_std'],data['employmentLength_debt_rate_max']\n",
    "del data['subGrade_interestRate_max'],data['homeOwnership_debt_rate_max']\n",
    "del data['employmentLength_debt_rate_std'],data['homeOwnership_revolBal_std'],data['employmentLength_revolBal_std']\n",
    "del data['subGrade_interestRate_mean'],data['employmentTitle_debt_rate_max']\n",
    "del data['annual_loanAmnt'],data['homeOwnership_revolBal_skew']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征编码\n",
    "- 自定义编码\n",
    "- count encoder 频数编码\n",
    "- one_hot Encoder 独热编码\n",
    "- label Encoder 标签编码\n",
    "- target Encoder 目标编码\n",
    "- mean Encoder 平均编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.自定义编码\n",
    "grade_dict = {'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7}\n",
    "data['grade'] = data['grade'].map(grade_dict).astype('int8')\n",
    "data['subGrade'] = data['subGrade'].astype('str').apply(lambda x:grade_dict[x[0]]*10 + int(x[1]))   \n",
    "employmentLength_dict = {\n",
    "        '< 1 year':0,\n",
    "        '1 year':1,\n",
    "        '2 years':2,\n",
    "        '3 years':3,\n",
    "        '4 years':4,\n",
    "        '5 years':5,\n",
    "        '6 years':6,\n",
    "        '7 years':7,\n",
    "        '8 years':8,\n",
    "        '9 years':9,\n",
    "        '10+ years':10\n",
    "        }\n",
    "data['employmentLength'] = data['employmentLength'].map(employmentLength_dict)\n",
    "\n",
    "# 数值特征重新编码：'ficoRangeLow'\n",
    "ficoRangeLow_dict = {}\n",
    "ficoRangeLow_list = list(data['ficoRangeLow'].sort_values().unique())\n",
    "for ind,val in enumerate(ficoRangeLow_list):\n",
    "    ficoRangeLow_dict[val] = ind\n",
    "data['ficoRangeLow'] = data['ficoRangeLow'].map(ficoRangeLow_dict).astype('int8')\n",
    "\n",
    "# 2.labelEncoder 编码\n",
    "high_cat = ['postCode','employmentTitle','title']\n",
    "for col in high_cat:\n",
    "    lbl = LabelEncoder().fit(data[col])\n",
    "    data[col] = lbl.transform(data[col])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. mean Encoder 平均编码\n",
    "\n",
    "cat_features = ['term','grade','subGrade','employmentLength','homeOwnership','verificationStatus','purpose',\n",
    "                'postCode','regionCode','initialListStatus','applicationType','employmentTitle','title','ficoRangeLow',\n",
    "                'issueDate_year','issueDate_month','issueDate_dayofweek','earliesCreditLine_year','earliesCreditLine_month',\n",
    "                'annualIncome_bin','loanAmnt_bin']\n",
    "\n",
    "data[cat_features] = data[cat_features].astype('str')\n",
    "X = data.drop('isDefault',axis=1)[:800000]\n",
    "y = data['isDefault'][:800000]\n",
    "test = data.drop('isDefault',axis=1)[800000:]\n",
    "\n",
    "\n",
    "MeanEncoderFeature = ['employmentLength','homeOwnership','annualIncome_bin']\n",
    "ME = Meancoder.MeanEncoder(MeanEncoderFeature,target_type='classification')\n",
    "X = ME.fit_transform(X,y)\n",
    "test = ME.transform(test)\n",
    "\n",
    "for feat in MeanEncoderFeature:\n",
    "    cat_features.remove(feat)\n",
    "\n",
    "X = X.drop(columns=MeanEncoderFeature,axis=1)\n",
    "test = test.drop(columns=MeanEncoderFeature,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合\n",
    "- 模型差异：（1）lightgbm （2）catboost （3）xgboost\n",
    "- 特征差异：（1）特征组合1 （2）特征组合2\n",
    "- 参数差异：（1）行采样比 bagging fraction （2）列采样比 feature fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型预测评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[cat_features] = X[cat_features].astype('str')\n",
    "test[cat_features] = test[cat_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_folds = 15,learning_rate=0.1,预测评分 0.7440\n",
    "\n",
    "sk=StratifiedKFold(n_splits=15,shuffle=True,random_state=42)\n",
    "\n",
    "pred_test = np.zeros(len(test)) \n",
    "auc_val = 0\n",
    "for fold,(train_idx,val_idx) in enumerate(sk.split(X,y)):\n",
    "    x_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    x_val = X.iloc[val_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(iterations=10000,\n",
    "                             learning_rate=0.1,\n",
    "                             depth=5, \n",
    "                             subsample=1,\n",
    "                             reg_lambda=5,\n",
    "                             loss_function='Logloss',\n",
    "                             custom_loss='AUC',\n",
    "                             eval_metric='AUC',\n",
    "                             random_seed=42,\n",
    "                             early_stopping_rounds=100)\n",
    "    \n",
    "    model.fit(x_train,y_train,\n",
    "        eval_set=(x_val,y_val),\n",
    "        cat_features=cat_features,\n",
    "        verbose=1000)\n",
    "    \n",
    "    pred_val = model.predict(x_val)\n",
    "    auc_val += roc_auc_score(pred_val,y_val)/sk.n_splits        \n",
    "    pred_test +=  model.predict_proba(test)[:,1]/sk.n_splits\n",
    "    \n",
    "print('catb auc:{:<8.8f}'.format(auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cat = pd.DataFrame()\n",
    "result_cat['id'] = test_data['id']           \n",
    "result_cat['isDefault'] = pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cat.to_csv('./result/result_cat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
